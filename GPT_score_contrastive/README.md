# Master's Thesis: Scoring of pronoun translation mistakes with ChatGPT

To explore whether the document-level version of [GEMBA](https://github.com/MicrosoftTranslator/GEMBA) is suitable for evaluating MT output at the document-level, this code was written to measure its sensitivity to discourse-level translation errors (see chapter 6.5 in thesis).

## Input
The program takes as input the data in the ```data/``` directory which contains original human reference translations (WMT newstest 2021 and generaltest 2022) along with perturbed reference translations, where mistranslations of the English pronoun "it" were added. References (both perturbed and original) are scored against a different reference translation.

To obtain the results reported in the thesis, the translations were scored as follows:

Newstest 2021:
* Reference A against Reference B
* Reference B against Reference A
* Reference C against Reference D
* Reference D against Reference C

Generaltest 2022:
* Reference A against Reference B

## Usage

Update the API key in ```api.py```.

Example program call:

```
python3 main.py --src data/newstest2021.en-de.src.en --hyp data/corrupted_news2021_refA.de \
    --ref data/newstest2021.en-de.ref.ref-B.de --indices data/idx_changes_news2021_refA.txt \
    --prompt-type doc_DA --save
```

The flag ```--prompt-type``` can be used to select either of the two prompts. The ```--save``` flag can be used to store the responses (scores and explanation for score) generated by ChatGPT.

To get scores for all the data (perturbed and original references scored against a secondary reference translation) used in the thesis, simply run the scoring bash script from the main directory:

```
bash score.sh
```

## Responses
For the newstest 2021 data, scores along with the generated answer text were stored in csv files in the ```gpt_responses/``` directory.